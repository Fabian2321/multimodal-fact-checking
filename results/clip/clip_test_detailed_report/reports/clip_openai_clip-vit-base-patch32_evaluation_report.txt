Evaluation Report
====================
Overall Accuracy: 0.6979
Macro Precision: 0.6979
Macro Recall: 0.7051
Macro F1-score: 0.6952


--- Classification Report (Per Class) ---
              precision    recall  f1-score   support

        Real       0.79      0.67      0.72        57
        Fake       0.60      0.74      0.67        39

    accuracy                           0.70        96
   macro avg       0.70      0.71      0.70        96
weighted avg       0.72      0.70      0.70        96

--- Placeholder for Advanced Explainability Metrics ---
Quality of generated explanations (human-annotated relevance): TODO
Visualization of attention weights or Grad-CAM heatmaps: TODO (qualitative analysis)
