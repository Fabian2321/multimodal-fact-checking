Evaluation Report
====================
Overall Accuracy: 0.7396
Macro Precision: 0.7334
Macro Recall: 0.7402
Macro F1-score: 0.7347


--- Classification Report (Per Class) ---
              precision    recall  f1-score   support

        Real       0.81      0.74      0.77        57
        Fake       0.66      0.74      0.70        39

    accuracy                           0.74        96
   macro avg       0.73      0.74      0.73        96
weighted avg       0.75      0.74      0.74        96

--- Placeholder for Advanced Explainability Metrics ---
Quality of generated explanations (human-annotated relevance): TODO
Visualization of attention weights or Grad-CAM heatmaps: TODO (qualitative analysis)
